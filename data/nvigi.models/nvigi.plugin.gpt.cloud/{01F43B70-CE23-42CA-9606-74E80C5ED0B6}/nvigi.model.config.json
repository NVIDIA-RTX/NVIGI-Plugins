{
  "name": "llama-3.2-3b-instruct",
  "vram": 0,
  "url": "https://integrate.api.nvidia.com/v1/chat/completions",
  "request_body": {
    "model": "meta/llama-3.2-3b-instruct",
    "messages": [
      {"role":"system","content":"$system"},
      {"role":"user","content":"$user"}
    ],
    "temperature": 0.2,
    "top_p": 0.7,
    "max_tokens": 1024,
    "stream": false
  }
}